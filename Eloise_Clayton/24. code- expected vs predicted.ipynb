{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2e3ee7-3fab-42f4-b140-ff24279472bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: RandomForest_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing, ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your dataset\n",
    "Dataset = pd.read_csv(\"full_descriptors.csv\")\n",
    "X = Dataset[['MW','volume','G_sol','DeltaG_sol','sol_dip',\n",
    "             'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "             'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "y = Dataset['LogS']\n",
    "\n",
    "# Initialize lists\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# 10-fold CV\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = ensemble.RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_true_all.extend(y_test)\n",
    "    y_pred_all.extend(y_pred)\n",
    "\n",
    "# Save predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'Experimental': y_true_all,\n",
    "    'Predicted': y_pred_all,\n",
    "    'Absolute Error': np.abs(np.array(y_true_all) - np.array(y_pred_all))\n",
    "})\n",
    "results_df.to_csv(\"RandomForest_predictions.csv\", index=False)\n",
    "print(\"Saved: RandomForest_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b981a824-eb3f-44f5-a75e-0c3b8c7d05a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: RandomForest_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing, ensemble\n",
    "\n",
    "# Load your dataset\n",
    "Dataset = pd.read_csv(\"full_descriptors.csv\")\n",
    "\n",
    "# Shuffle the dataset like in your original code\n",
    "Dataset = Dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Define input features and target\n",
    "X = Dataset[['MW','volume','G_sol','DeltaG_sol','sol_dip',\n",
    "             'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "             'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "y = Dataset['LogS']\n",
    "\n",
    "# Set up cross-validation (no random_state, no shuffle — same as your original code)\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Lists to collect results\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "# Run 10-fold CV for Random Forest\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Standardize features (like your original)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train Random Forest\n",
    "    model = ensemble.RandomForestRegressor(n_estimators=500, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Save results\n",
    "    y_true_all.extend(y_test)\n",
    "    y_pred_all.extend(y_pred)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Experimental': y_true_all,\n",
    "    'Predicted': y_pred_all,\n",
    "    'Absolute Error': np.abs(np.array(y_true_all) - np.array(y_pred_all))\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(\"RandomForest_predictions.csv\", index=False)\n",
    "print(\"✅ Saved: RandomForest_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735e0075-21ea-480c-80e1-59db3528215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load and shuffle dataset\n",
    "Dataset = pd.read_csv(\"full_descriptors.csv\")\n",
    "Dataset = Dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Features and target\n",
    "X = Dataset[['MW','volume','G_sol','DeltaG_sol','sol_dip',\n",
    "             'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "             'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "y = Dataset['LogS']\n",
    "\n",
    "# Set up 10-fold CV\n",
    "kf = KFold(n_splits=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c60ac50-ab31-4dbb-9175-cd3c6d8f8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"MLR_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784f31cb-e8bb-4b86-a6c7-dda1314d44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=300, max_iter=800)\n",
    "    for _ in range(100):\n",
    "        try:\n",
    "            mlp.fit(X_train, y_train)\n",
    "            preds = mlp.predict(X_test)\n",
    "            if np.ptp(preds) == 0:\n",
    "                continue\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"ANN_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfa2237-52a2-42ed-8dc3-f18817a187e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = svm.SVR(C=4, epsilon=0.01, gamma=0.03, kernel='rbf')\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"SVM_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee82bc4-5f7d-475a-8384-7da41e02370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = PLSRegression(n_components=9)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test).flatten()  # reshape\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"PLS_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409bcbe9-86c5-4325-bc3b-b253f30183d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = ensemble.ExtraTreesRegressor(n_estimators=500, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"ExtraTrees_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fcd845d-8f87-4593-b008-3244b8318ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = ensemble.BaggingRegressor(n_estimators=500, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"Bagging_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367a097-eaf2-4d6e-9030-6a8175d1b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "import GPy\n",
    "\n",
    "# Store results\n",
    "true_vals = []\n",
    "pred_vals = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    y_train_array = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "    # GPR with RBF kernel\n",
    "    kernel = GPy.kern.RBF(input_dim=X_train.shape[1])\n",
    "    model = GPy.models.GPRegression(X_train, y_train_array, kernel)\n",
    "    model.optimize()\n",
    "\n",
    "    preds = model.predict(X_test)[0].flatten()\n",
    "\n",
    "    true_vals.extend(y_test)\n",
    "    pred_vals.extend(preds)\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({\n",
    "    'Experimental': true_vals,\n",
    "    'Predicted': pred_vals,\n",
    "    'Absolute Error': np.abs(np.array(true_vals) - np.array(pred_vals))\n",
    "}).to_csv(\"GPR_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457725a8-4c90-4261-836c-d16ac8062825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
