{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a3dd3e-f395-4e84-afa9-7455a4cb9db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n",
      "/tmp/ipykernel_349/1748793906.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pls2preds2.append(float(i))\n"
     ]
    }
   ],
   "source": [
    "import sys,os,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics\n",
    "\n",
    "# load full_descriptors.csv which contains all descriptors and information- externally created\n",
    "Dataset=pd.read_csv(\"full_descriptors.csv\")\n",
    "output_metrics=(\"MLCV_metrics.csv\")\n",
    "\n",
    "#Define statistical measures and R2 conversion\n",
    "#define RMSE\n",
    "def rmse(predictions, targets):\n",
    "\treturn np.sqrt(((predictions - targets) ** 2).mean())\n",
    "#define % within certain range\n",
    "def within_range(list1, list2, range2):\n",
    "\tx=0\n",
    "\tfor i in range(len(list2)):\n",
    "\t\tif (list1[i]-range2)<= list2[i] <= (list1[i]+range2): \n",
    "\t\t\tx+=1\n",
    "\treturn((float(x)/(len(list2)))*100)\n",
    "#define getting R2 method\n",
    "def get_R2(R2):\n",
    "\tR2_2=[]\n",
    "\tfor i in range(len(R2)):\n",
    "\t\tx=re.findall('\\d\\.\\d+',str(R2[i]))\n",
    "\t\tj=float(x[0])\n",
    "\t\tj=j**2\n",
    "\t\tR2_2.append(j)\n",
    "\treturn(R2_2)\n",
    "#define method to get CV results\n",
    "def CV_metrics(Data,folds,C,E,G):\n",
    "\t#initiate lists to add metrics to (one for )\n",
    "\tRMSE=[]\n",
    "\tR2=[]\n",
    "\tN1=[]\n",
    "\tN05=[]\n",
    "\tMLR_RMSE=[]\n",
    "\tMLR_R2=[]\n",
    "\tMLR_N1=[]\n",
    "\tMLR_N05=[]\n",
    "\tANN_RMSE=[]\n",
    "\tANN_R2=[]\n",
    "\tANN_N1=[]\n",
    "\tANN_N05=[]\n",
    "\tSVM_RMSE=[]\n",
    "\tSVM_R2=[]\n",
    "\tSVM_N1=[]\n",
    "\tSVM_N05=[]\n",
    "\tPLS_RMSE=[]\n",
    "\tPLS_R2=[]\n",
    "\tPLS_N1=[]\n",
    "\tPLS_N05=[]\n",
    "\tRF_RMSE=[]\n",
    "\tRF_R2=[]\n",
    "\tRF_N1=[]\n",
    "\tRF_N05=[]\n",
    "\tET_RMSE=[]\n",
    "\tET_R2=[]\n",
    "\tET_N1=[]\n",
    "\tET_N05=[]\n",
    "\tBG_RMSE=[]\n",
    "\tBG_R2=[]\n",
    "\tBG_N1=[]\n",
    "\tBG_N05=[]\n",
    "\t#import Data and randomise\n",
    "\tX = Data\n",
    "\tX = X.sample(frac=1).reset_index(drop=True)\n",
    "\t#define k-fold cross validation and make k splits\n",
    "\tcol_names=X.dtypes.index\n",
    "\tX = np.array(X)\n",
    "\tkf = KFold(n_splits=folds)\n",
    "\t#for every split\n",
    "\tfor train1, test1 in kf.split(X):\n",
    "\t\ttrain=X[train1]\n",
    "\t\ttest=X[test1]\n",
    "\t\ttrain=pd.DataFrame(data=train, columns=col_names)\n",
    "\t\ttest=pd.DataFrame(data=test, columns=col_names)\n",
    "\t\tX_train = train[['MW','volume','G_sol','DeltaG_sol','sol_dip',\n",
    "\t\t\t\t\t 'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "\t\t\t\t\t 'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "\t\ty_train = train['LogS']\n",
    "\t\tX_test = test[['MW', 'volume','G_sol','DeltaG_sol','sol_dip',\n",
    "\t\t\t\t\t 'Lsolu_Hsolv','Lsolv_Hsolu','SASA','O_charges',\n",
    "\t\t\t\t\t 'C_charges','Most_neg','Most_pos','Het_charges']]\n",
    "\t\ty_test = test['LogS']\n",
    "\t\ty_test=np.array(y_test)\n",
    "\t\tscaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\t\tX_train = scaler.transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\t\t#run models\n",
    "\t\t#MLR\n",
    "\t\tmlr = LinearRegression()\n",
    "\t\tmlr.fit(X_train, y_train)\n",
    "\t\tmlr2preds = mlr.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tMLR_R2.append(pearsonr(mlr2preds, y_test))\n",
    "\t\tMLR_RMSE.append(rmse(mlr2preds, y_test))\n",
    "\t\tMLR_N1.append(within_range(y_test,mlr2preds,1))\n",
    "\t\tMLR_N05.append(within_range(y_test,mlr2preds,0.7))\n",
    "\t\t#ANN\n",
    "\t\tmlp = MLPRegressor(hidden_layer_sizes=300,max_iter=800)\n",
    "\t\tfor f in range(100):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tmlp.fit(X_train, y_train)\n",
    "\t\t\t\tmlp2preds = mlp.predict(X_test)\n",
    "\t\t\t\tif np.ptp(mlp2preds) == 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tbreak\n",
    "\t\t\texcept:\n",
    "\t\t\t\tcontinue\n",
    "\t\t#evaluate model\n",
    "\t\tANN_R2.append(pearsonr(mlp2preds, y_test))\n",
    "\t\tANN_RMSE.append(rmse(mlp2preds, y_test))\n",
    "\t\tANN_N1.append(within_range(y_test,mlp2preds,1))\n",
    "\t\tANN_N05.append(within_range(y_test,mlp2preds,0.7))\n",
    "\t\t#SVM\n",
    "\t\tsvm2 = svm.SVR(C = C, epsilon = E, gamma = G, kernel = 'rbf')\n",
    "\t\tsvm2.fit(X_train, y_train)\n",
    "\t\tsvm2preds = svm2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tSVM_R2.append(pearsonr(svm2preds, y_test))\n",
    "\t\tSVM_RMSE.append(rmse(svm2preds, y_test))\n",
    "\t\tSVM_N1.append(within_range(y_test,svm2preds,1))\n",
    "\t\tSVM_N05.append(within_range(y_test,svm2preds,0.7))\n",
    "\t\t#PLS\n",
    "\t\tpls2 = PLSRegression(n_components=9)\n",
    "\t\tpls2.fit(X_train, y_train)\n",
    "\t\tpls2preds = pls2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\t#convert to float (comes in weird type?)\n",
    "\t\tpls2preds2=[]\n",
    "\t\tfor i in pls2preds:\n",
    "\t\t\tpls2preds2.append(float(i))\n",
    "\t\tPLS_R2.append(pearsonr(pls2preds2, y_test))\n",
    "\t\tPLS_RMSE.append(rmse(pls2preds2, y_test))\n",
    "\t\tPLS_N1.append(within_range(y_test,pls2preds2,1))\n",
    "\t\tPLS_N05.append(within_range(y_test,pls2preds2,0.7))\n",
    "\t\t#RF\n",
    "\t\ttree2 = ensemble.RandomForestRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree2.fit(X_train, y_train)\n",
    "\t\ttree2preds = tree2.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tRF_R2.append(pearsonr(tree2preds, y_test))\n",
    "\t\tRF_RMSE.append(rmse(tree2preds, y_test))\n",
    "\t\tRF_N1.append(within_range(y_test,tree2preds,1))\n",
    "\t\tRF_N05.append(within_range(y_test,tree2preds,0.7))\n",
    "\t\t#ExtraTrees\n",
    "\t\ttree3 = ensemble.ExtraTreesRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree3.fit(X_train, y_train)\n",
    "\t\ttree3preds = tree3.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tET_R2.append(pearsonr(tree3preds, y_test))\n",
    "\t\tET_RMSE.append(rmse(tree3preds, y_test))\n",
    "\t\tET_N1.append(within_range(y_test,tree3preds,1))\n",
    "\t\tET_N05.append(within_range(y_test,tree3preds,0.7))\n",
    "\t\t#Bagging\n",
    "\t\ttree4 = ensemble.BaggingRegressor(n_estimators=500,n_jobs=-1)\n",
    "\t\ttree4.fit(X_train, y_train)\n",
    "\t\ttree4preds = tree4.predict(X_test)\n",
    "\t\t#evaluate model\n",
    "\t\tBG_R2.append(pearsonr(tree4preds, y_test))\n",
    "\t\tBG_RMSE.append(rmse(tree4preds, y_test))\n",
    "\t\tBG_N1.append(within_range(y_test,tree4preds,1))\n",
    "\t\tBG_N05.append(within_range(y_test,tree4preds,0.7))\n",
    "\t#get R2 from Pearson output\n",
    "\tMLR_R2=get_R2(MLR_R2)\n",
    "\tANN_R2=get_R2(ANN_R2)\n",
    "\tSVM_R2=get_R2(SVM_R2)\n",
    "\tPLS_R2=get_R2(PLS_R2)\n",
    "\tRF_R2=get_R2(RF_R2)\n",
    "\tET_R2=get_R2(ET_R2)\n",
    "\tBG_R2=get_R2(BG_R2)\n",
    "\t#get mean metrics and put together in lists\n",
    "\tR2.append(statistics.mean(MLR_R2))\n",
    "\tRMSE.append(statistics.mean(MLR_RMSE))\n",
    "\tN1.append(statistics.mean(MLR_N1))\n",
    "\tN05.append(statistics.mean(MLR_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(ANN_R2))\n",
    "\tRMSE.append(statistics.mean(ANN_RMSE))\n",
    "\tN1.append(statistics.mean(ANN_N1))\n",
    "\tN05.append(statistics.mean(ANN_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(SVM_R2))\n",
    "\tRMSE.append(statistics.mean(SVM_RMSE))\n",
    "\tN1.append(statistics.mean(SVM_N1))\n",
    "\tN05.append(statistics.mean(SVM_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(PLS_R2))\n",
    "\tRMSE.append(statistics.mean(PLS_RMSE))\n",
    "\tN1.append(statistics.mean(PLS_N1))\n",
    "\tN05.append(statistics.mean(PLS_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(RF_R2))\n",
    "\tRMSE.append(statistics.mean(RF_RMSE))\n",
    "\tN1.append(statistics.mean(RF_N1))\n",
    "\tN05.append(statistics.mean(RF_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(ET_R2))\n",
    "\tRMSE.append(statistics.mean(ET_RMSE))\n",
    "\tN1.append(statistics.mean(ET_N1))\n",
    "\tN05.append(statistics.mean(ET_N05))\n",
    "\t#\n",
    "\tR2.append(statistics.mean(BG_R2))\n",
    "\tRMSE.append(statistics.mean(BG_RMSE))\n",
    "\tN1.append(statistics.mean(BG_N1))\n",
    "\tN05.append(statistics.mean(BG_N05))\n",
    "\t#\n",
    "\t#create dataframe of metrics\n",
    "\tModels=[\"MLR\",\"ANN\",\"SVM\",\"PLS\",\"RF\",\"ExtraTrees\",\"Bagging\"]\n",
    "\tMetrics=list(zip(Models,R2,RMSE,N1,N05))\n",
    "\tMetrics_df=pd.DataFrame(data=Metrics, columns=['Model','R2','RMSE','% within 1','% within 0.7'])\n",
    "\treturn(Metrics_df)\n",
    "##method to put it all together\n",
    "def get_CV_metrics(Dataset,output_metrics):\n",
    "\t##get metrics\n",
    "\tCV_metrics2=CV_metrics(Dataset,10,4,0.01,0.03)##10-folds and SVM parameters\n",
    "\t##save to file\n",
    "\tCV_metrics2.to_csv(output_metrics,index=False)\n",
    "\n",
    "##section 4: run CV method and get metrics\n",
    "get_CV_metrics(Dataset,output_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe19350-295e-4f63-adeb-4c5bfed33133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
