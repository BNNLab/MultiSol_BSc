{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path containing gas phase calculations\n",
    "gas_path = '/Users/stella/Documents/tierney/project/output MOPAC/gas_mopac_files' \n",
    "# path containing solution phase calculation\n",
    "sol_path = '/Users/stella/Documents/tierney/project/output MOPAC/sol_mopac_files' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermodynamic data written to gas_phase_thermo_data.csv\n",
      "                         InChIkey    H_gas    S_gas\n",
      "0     CMWTZPSULFXXJA-GTNTULIANA-N  10510.0  128.280\n",
      "1     YASYVMFAVPKPKE-JSWHHWTPNA-N   8749.1  113.838\n",
      "2     GVIJJXMXTUZIOD-UHFFFAOYNA-N   7228.7  101.488\n",
      "3     QUEKGYQTRJVEQC-KZFATGLANA-N   7284.9  103.513\n",
      "4     DAUAQNGYDSHRET-KZFATGLANA-N   8280.9  108.438\n",
      "...                           ...      ...      ...\n",
      "3759  CMWTZPSULFXXJA-GTNTULIANA-N  10482.4  127.440\n",
      "3760  GVIJJXMXTUZIOD-UHFFFAOYNA-N   7531.9  102.196\n",
      "3761  PJANXHGTPQOBST-VAWYXSNFNA-N   7806.0  104.500\n",
      "3762  CIWBSHSKHKDKBQ-JLAZNSOCNA-N   8386.9  109.398\n",
      "3763  GJCOSYZMQJWQCA-UHFFFAOYNA-N   6901.8   96.774\n",
      "\n",
      "[3764 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_aux_file(filename, gas_path):\n",
    "    \"\"\"Process .aux files to extract thermodynamic data\"\"\"\n",
    "    try:\n",
    "        # Extract InChIkey from filename (PM6_{inchikey}_{count}.aux)\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            inchikey = parts[1]  # Second part is the InChIKey\n",
    "            compound = inchikey  # Using InChIKey as compound name\n",
    "            \n",
    "            # Initialize variables\n",
    "            enthalpy = None\n",
    "            entropy = None\n",
    "            \n",
    "            # Read .aux file\n",
    "            full_filename = os.path.join(gas_path, filename)\n",
    "            with open(full_filename, 'r', encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                \n",
    "                # Extract enthalpy (first value at 298K)\n",
    "                enthalpy_match = re.search(r'ENTHALPY_TOT:CAL/MOL\\[\\d+\\]=\\s+([\\d.\\s-]+)', content)\n",
    "                if enthalpy_match:\n",
    "                    enthalpy = enthalpy_match.group(1).split()[0]\n",
    "                \n",
    "                # Extract entropy (first value at 298K)\n",
    "                entropy_match = re.search(r'ENTROPY_TOT:CAL/K/MOL\\[\\d+\\]=\\s+([\\d.\\s-]+)', content)\n",
    "                if entropy_match:\n",
    "                    entropy = entropy_match.group(1).split()[0]\n",
    "                \n",
    "                if enthalpy and entropy:\n",
    "                    return {\n",
    "                        'InChIkey': inchikey,\n",
    "                        'H_gas': enthalpy,\n",
    "                        'S_gas': entropy\n",
    "                    }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "    return None\n",
    "\n",
    "def extract_thermo_data(gas_path, output_filename):\n",
    "    \"\"\"Process all .aux files in directory and save results to CSV\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for filename in os.listdir(gas_path):\n",
    "        if filename.startswith('PM6_') and filename.endswith('.aux'):\n",
    "            result = process_aux_file(filename, gas_path)\n",
    "            if result:\n",
    "                rows.append(result)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    if rows:\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(output_filename, index=False)\n",
    "        print(f\"Thermodynamic data written to {output_filename}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No valid .aux files found with thermodynamic data\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Main execution\n",
    "gas_path = '/Users/stella/Documents/tierney/project/output MOPAC/gas_mopac_files'\n",
    "thermo_data = extract_thermo_data(gas_path, 'gas_phase_thermo_data.csv')\n",
    "\n",
    "# Display results\n",
    "print(thermo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InChIkey    object\n",
      "H_gas       object\n",
      "S_gas       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(thermo_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermo_data['H_gas'] = pd.to_numeric(thermo_data['H_gas'], errors='coerce')\n",
    "thermo_data['S_gas'] = pd.to_numeric(thermo_data['S_gas'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_thermo_data = thermo_data.groupby('InChIkey').mean().reset_index()\n",
    "gas_thermo_data.to_csv('ave_gas_thermo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution phase thermodynamic data written to sol_thermo_data.csv\n",
      "Found 3249 solute-solvent pairs\n",
      "Unique solutes: 283\n",
      "Unique solvents: 84\n",
      "                      InChIkey             Solvent   H_sol    S_sol\n",
      "0  GVEPBJHOBDJJJI-UHFFFAOYNA-N          chloroform  7570.9  102.618\n",
      "1  GVIJJXMXTUZIOD-UHFFFAOYNA-N         1,4-dioxane  7720.1  104.363\n",
      "2  WBYWAXJHAXSJNI-KZFATGLANA-N             acetone  6928.1   99.698\n",
      "3  RYYVLZVUVIJVGH-UHFFFAOYNA-N             acetone  9122.7  115.734\n",
      "4  GPSDUZXPYCFOSQ-BGGKNDAXNA-N  2-methyl-1-butanol  6621.6   96.033\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_sol_file(filename, sol_path):\n",
    "    \"\"\"Process solution phase .aux files to extract thermodynamic data and solvent info\"\"\"\n",
    "    try:\n",
    "        # Extract InChIkey and solvent from filename (PM6_{solute_inchikey}_{solvent_name}.aux)\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            inchikey = parts[1]  # Second part is the solute InChIKey\n",
    "            solvent = parts[2].replace('.aux', '')  # Third part is solvent name\n",
    "            compound = inchikey  # Using InChIKey as compound name\n",
    "            \n",
    "            # Initialize variables\n",
    "            enthalpy = None\n",
    "            entropy = None\n",
    "            \n",
    "            # Read .aux file\n",
    "            full_filename = os.path.join(sol_path, filename)\n",
    "            with open(full_filename, 'r', encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                \n",
    "                # Extract enthalpy (first value at 298K)\n",
    "                enthalpy_match = re.search(r'ENTHALPY_TOT:CAL/MOL\\[\\d+\\]=\\s+([\\d.\\s-]+)', content)\n",
    "                if enthalpy_match:\n",
    "                    enthalpy = enthalpy_match.group(1).split()[0]\n",
    "                \n",
    "                # Extract entropy (first value at 298K)\n",
    "                entropy_match = re.search(r'ENTROPY_TOT:CAL/K/MOL\\[\\d+\\]=\\s+([\\d.\\s-]+)', content)\n",
    "                if entropy_match:\n",
    "                    entropy = entropy_match.group(1).split()[0]\n",
    "                \n",
    "                if enthalpy and entropy:\n",
    "                    return {\n",
    "                        'InChIkey': inchikey,\n",
    "                        'Solvent': solvent,\n",
    "                        'H_sol': enthalpy,\n",
    "                        'S_sol': entropy\n",
    "                    }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {str(e)}\")\n",
    "    return None\n",
    "\n",
    "def extract_sol_data(sol_path, output_filename):\n",
    "    \"\"\"Process all solution phase .aux files in directory and save results to CSV\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for filename in os.listdir(sol_path):\n",
    "        if filename.startswith('PM6_') and filename.endswith('.aux'):\n",
    "            result = process_sol_file(filename, sol_path)\n",
    "            if result:\n",
    "                rows.append(result)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    if rows:\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(output_filename, index=False)\n",
    "        print(f\"Solution phase thermodynamic data written to {output_filename}\")\n",
    "        print(f\"Found {len(df)} solute-solvent pairs\")\n",
    "        print(f\"Unique solutes: {df['InChIkey'].nunique()}\")\n",
    "        print(f\"Unique solvents: {df['Solvent'].nunique()}\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No valid solution phase .aux files found with thermodynamic data\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Main execution - Solution Phase Only\n",
    "sol_path = '/Users/stella/Documents/tierney/project/output MOPAC/sol_mopac_files'\n",
    "sol_thermo_data = extract_sol_data(sol_path, 'sol_thermo_data.csv')\n",
    "\n",
    "# Display solution phase results\n",
    "print(sol_thermo_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row count: 3249\n"
     ]
    }
   ],
   "source": [
    "# merging dataframes from gas and solution calculations\n",
    "df_thermo = pd.merge(gas_thermo_data, sol_thermo_data, on='InChIkey')\n",
    "print(f\"row count: {len(df_thermo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermodynamic data written to G_sol_thermo_data.csv\n",
      "row count: 3249\n"
     ]
    }
   ],
   "source": [
    "# calculate G_sol and DeltaG_sol descriptors, and remove the rest\n",
    "# of the data from df_thermo\n",
    "\n",
    "df_thermo['H_gas'] = df_thermo['H_gas'].astype(float)\n",
    "df_thermo['S_gas'] = df_thermo['S_gas'].astype(float)\n",
    "df_thermo['H_sol'] = df_thermo['H_sol'].astype(float)\n",
    "df_thermo['S_sol'] = df_thermo['S_sol'].astype(float)\n",
    "df_thermo['G_gas'] = df_thermo['H_gas']-(df_thermo['S_gas']*298)\n",
    "df_thermo['G_sol'] = df_thermo['H_sol']-(df_thermo['S_sol']*298)\n",
    "df_thermo['DeltaG_sol'] = df_thermo['G_sol']-df_thermo['G_gas']\n",
    "df_thermo.drop(['H_gas', 'S_gas', 'H_sol', 'S_sol', 'G_gas'], axis = 1)\n",
    "\n",
    "# Save the processed DataFrame to a CSV file\n",
    "output_filename = 'G_sol_thermo_data.csv'\n",
    "df_thermo.to_csv(output_filename, index=False)\n",
    "print(f\"Thermodynamic data written to {output_filename}\")\n",
    "print(f\"row count: {len(df_thermo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermodynamic data written to G_thermo_data.csv\n",
      "Final columns: ['InChIkey', 'Solvent', 'G_sol', 'DeltaG_sol']\n",
      "row count: 3249\n"
     ]
    }
   ],
   "source": [
    "# Calculate thermodynamic descriptors\n",
    "df_thermo['H_gas'] = df_thermo['H_gas'].astype(float)\n",
    "df_thermo['S_gas'] = df_thermo['S_gas'].astype(float)\n",
    "df_thermo['H_sol'] = df_thermo['H_sol'].astype(float)\n",
    "df_thermo['S_sol'] = df_thermo['S_sol'].astype(float)\n",
    "\n",
    "# Calculate Gibbs free energies\n",
    "df_thermo['G_gas'] = df_thermo['H_gas'] - (df_thermo['S_gas'] * 298)\n",
    "df_thermo['G_sol'] = df_thermo['H_sol'] - (df_thermo['S_sol'] * 298)\n",
    "df_thermo['DeltaG_sol'] = df_thermo['G_sol'] - df_thermo['G_gas']\n",
    "\n",
    "# Remove intermediate columns (using inplace)\n",
    "df_thermo.drop(['H_gas', 'S_gas', 'H_sol', 'S_sol', 'G_gas'], axis=1, inplace=True)\n",
    "\n",
    "# Save the processed DataFrame\n",
    "output_filename = 'G_thermo_data.csv'\n",
    "df_thermo.to_csv(output_filename, index=False)\n",
    "print(f\"Thermodynamic data written to {output_filename}\")\n",
    "print(f\"Final columns: {df_thermo.columns.tolist()}\")\n",
    "print(f\"row count: {len(df_thermo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# will read straight from solution structures and bypass gas phase structures\n",
    "\n",
    "df_dip_vol = pd.DataFrame(columns = ['volume', 'sol_dip'])\n",
    "\n",
    "for filename in os.listdir(sol_path):\n",
    "    if filename.endswith('.aux'):\n",
    "        # Extract the InChIKey from the filename\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3 and parts[0] == 'PM6':\n",
    "            solute_inchikey = parts[1]  # Extract the solute InChIKey\n",
    "            solvent = parts[2].replace('.aux', '')  # Third part is solvent name\n",
    "        # open aux file\n",
    "        full_filename = os.path.join(sol_path, filename)\n",
    "        f = open(full_filename, 'r')\n",
    "        # find thermodynamic values\n",
    "        for line in f:\n",
    "            if 'DIPOLE' in line:\n",
    "                dipole_line = line.split('=')\n",
    "                sol_dip_string = dipole_line[1].replace('\\n','')\n",
    "                sol_dip_string = sol_dip_string.replace('+','',1)\n",
    "                sol_dip_string_split = sol_dip_string.split('D')\n",
    "                sol_dip = float(sol_dip_string_split[0])*pow(10,float(sol_dip_string_split[1]))\n",
    "                # print('sol_dip (Debye) =', sol_dip)\n",
    "            if 'VOLUME' in line:\n",
    "                volume_line = line.split('=')\n",
    "                volume_string = volume_line[1].replace('\\n','')\n",
    "                volume_string = volume_string.replace('+','',1)\n",
    "                volume_string_split = volume_string.split('D')\n",
    "                volume = float(volume_string_split[0])*pow(10,float(volume_string_split[1]))\n",
    "                # print('volume (A^3)=', volume)\n",
    "        # save extracted data to dataframe\n",
    "        new_row = {'InChIkey':solute_inchikey,'Solvent':solvent, 'volume':volume, 'sol_dip':sol_dip}\n",
    "        df_dip_vol = pd.concat([df_dip_vol, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df_dip_vol\n",
    "df_dip_vol.to_csv('/Users/stella/Documents/tierney/project/dip_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/ptj22ckn1lq9dwc6k6bwvz580000gn/T/ipykernel_17972/2454948096.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_dip_vol = pd.concat([df_dip_vol, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1206 files. Skipped 2043 files (see skipped_files.log).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_scientific_number(s):\n",
    "    \"\"\"Parse numbers like '+0.325051D+00' or '0.243071E+03' into floats.\"\"\"\n",
    "    s = s.strip().replace('+', '').replace(' ', '')\n",
    "    if 'D' in s:\n",
    "        base, exponent = s.split('D')\n",
    "    elif 'E' in s:\n",
    "        base, exponent = s.split('E')\n",
    "    else:\n",
    "        return float(s)  # No exponent\n",
    "    return float(base) * 10 ** float(exponent)\n",
    "\n",
    "# Initialize DataFrame\n",
    "df_dip_vol = pd.DataFrame(columns=['InChikey', 'Solvent', 'volume', 'sol_dip'])\n",
    "skipped_files = []\n",
    "\n",
    "for filename in os.listdir(sol_path):\n",
    "    if filename.endswith('.aux'):\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 3 and parts[0] == 'PM6':\n",
    "            solute_inchikey = parts[1]\n",
    "            solvent = parts[2].replace('.aux', '')\n",
    "        else:\n",
    "            skipped_files.append(f\"{filename}: Malformed filename\")\n",
    "            continue\n",
    "\n",
    "        full_path = os.path.join(sol_path, filename)\n",
    "        try:\n",
    "            with open(full_path, 'r') as f:\n",
    "                content = f.read()\n",
    "\n",
    "                # Case-insensitive search for DIPOLE\n",
    "                dipole_match = re.search(r'DIPOLE:DEBYE\\s*=\\s*([+-]?\\d+\\.\\d+D[+-]?\\d+)', content, re.IGNORECASE)\n",
    "                if not dipole_match:\n",
    "                    skipped_files.append(f\"{filename}: Missing DIPOLE\")\n",
    "                    continue\n",
    "                sol_dip = parse_scientific_number(dipole_match.group(1))\n",
    "\n",
    "                # Case-insensitive search for VOLUME\n",
    "                volume_match = re.search(r'VOLUME:CUBIC ANGSTROMS\\s*=\\s*([+-]?\\d+\\.\\d+D[+-]?\\d+)', content, re.IGNORECASE)\n",
    "                if not volume_match:\n",
    "                    skipped_files.append(f\"{filename}: Missing VOLUME\")\n",
    "                    continue\n",
    "                volume = parse_scientific_number(volume_match.group(1))\n",
    "\n",
    "                # Add to DataFrame\n",
    "                new_row = {\n",
    "                    'InChikey': solute_inchikey,\n",
    "                    'Solvent': solvent,\n",
    "                    'volume': volume,\n",
    "                    'sol_dip': sol_dip\n",
    "                }\n",
    "                df_dip_vol = pd.concat([df_dip_vol, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            skipped_files.append(f\"{filename}: Error reading file ({str(e)})\")\n",
    "            continue\n",
    "\n",
    "# Save results\n",
    "df_dip_vol.to_csv('dipole_vol_data.csv', index=False)\n",
    "\n",
    "# Log skipped files\n",
    "with open('skipped_files.log', 'w') as f:\n",
    "    f.write(\"\\n\".join(skipped_files))\n",
    "\n",
    "print(f\"Processed {len(df_dip_vol)} files. Skipped {len(skipped_files)} files (see skipped_files.log).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM6_1_octanol.aux - HOMO: -10.392 eV, LUMO: 2.809 eV\n",
      "PM6_propylene_glycol.aux - HOMO: -10.492 eV, LUMO: 2.203 eV\n",
      "PM6_acetic_acid.aux - HOMO: -11.368 eV, LUMO: 0.429 eV\n",
      "PM6_toluene.aux - HOMO: -9.283 eV, LUMO: 0.447 eV\n",
      "PM6_nonane.aux - HOMO: -10.800 eV, LUMO: 4.006 eV\n",
      "PM6_formamide.aux - HOMO: -10.614 eV, LUMO: 0.922 eV\n",
      "PM6_chloroform.aux - HOMO: -11.344 eV, LUMO: -0.696 eV\n",
      "PM6_3_methyl_1_butanol.aux - HOMO: -10.196 eV, LUMO: 2.981 eV\n",
      "PM6_hexane.aux - HOMO: -11.015 eV, LUMO: 4.396 eV\n",
      "PM6_THF.aux - HOMO: -9.540 eV, LUMO: 2.345 eV\n",
      "PM6_cis_1_4_dimethylcyclohexane.aux - HOMO: -10.566 eV, LUMO: 4.044 eV\n",
      "PM6_heptane.aux - HOMO: -11.017 eV, LUMO: 4.067 eV\n",
      "PM6_benzene.aux - HOMO: -9.662 eV, LUMO: 0.389 eV\n",
      "PM6_ethylbenzene.aux - HOMO: -9.305 eV, LUMO: 0.467 eV\n",
      "PM6_1_2_dichloroethane.aux - HOMO: -10.790 eV, LUMO: 0.425 eV\n",
      "PM6_2_methyl_1_propanol.aux - HOMO: -10.254 eV, LUMO: 2.927 eV\n",
      "PM6_propionitrile.aux - HOMO: -12.372 eV, LUMO: 1.294 eV\n",
      "PM6_cyclohexane.aux - HOMO: -10.594 eV, LUMO: 4.148 eV\n",
      "PM6_m_xylene.aux - HOMO: -9.105 eV, LUMO: 0.558 eV\n",
      "PM6_water.aux - HOMO: -11.768 eV, LUMO: 3.957 eV\n",
      "PM6_acetone.aux - HOMO: -10.237 eV, LUMO: 0.615 eV\n",
      "PM6_2_isopropoxyethanol.aux - HOMO: -9.894 eV, LUMO: 1.806 eV\n",
      "PM6_2_propanol.aux - HOMO: -10.545 eV, LUMO: 2.995 eV\n",
      "PM6_methanol.aux - HOMO: -10.503 eV, LUMO: 2.772 eV\n",
      "PM6_1_tert_butoxy_2_propanol.aux - HOMO: -9.886 eV, LUMO: 1.865 eV\n",
      "PM6_DMF.aux - HOMO: -9.435 eV, LUMO: 1.134 eV\n",
      "PM6_propylene_carbonate.aux - HOMO: -10.900 eV, LUMO: 0.774 eV\n",
      "PM6_2_methyl_2_butanol.aux - HOMO: -10.311 eV, LUMO: 3.110 eV\n",
      "PM6_1_decanol.aux - HOMO: -10.393 eV, LUMO: 2.920 eV\n",
      "PM6_acetophenone.aux - HOMO: -10.012 eV, LUMO: -0.598 eV\n",
      "PM6_cyclohexanone.aux - HOMO: -9.910 eV, LUMO: 0.659 eV\n",
      "PM6_cis_1_3_dimethylcyclohexane.aux - HOMO: -10.533 eV, LUMO: 4.012 eV\n",
      "PM6_trans_1_2_dimethylcyclohexane.aux - HOMO: -10.559 eV, LUMO: 3.960 eV\n",
      "PM6_2_methyl_1_butanol.aux - HOMO: -10.208 eV, LUMO: 2.871 eV\n",
      "PM6_1_chlorobutane.aux - HOMO: -10.540 eV, LUMO: 1.017 eV\n",
      "PM6_dichloroethane.aux - HOMO: -10.945 eV, LUMO: 0.167 eV\n",
      "PM6_sulfolane.aux - HOMO: -10.770 eV, LUMO: 0.713 eV\n",
      "PM6_nitromethane.aux - HOMO: -11.399 eV, LUMO: -0.749 eV\n",
      "PM6_acetonitrile.aux - HOMO: -12.783 eV, LUMO: 1.317 eV\n",
      "PM6_chlorocyclohexane.aux - HOMO: -10.345 eV, LUMO: 1.190 eV\n",
      "PM6_2_methyl_1_pentanol.aux - HOMO: -10.209 eV, LUMO: 2.858 eV\n",
      "PM6_butyronitrile.aux - HOMO: -12.104 eV, LUMO: 1.348 eV\n",
      "PM6_1_heptanol.aux - HOMO: -10.362 eV, LUMO: 2.766 eV\n",
      "PM6_N_methylformamide.aux - HOMO: -9.962 eV, LUMO: 1.024 eV\n",
      "PM6_methylcyclohexane.aux - HOMO: -10.654 eV, LUMO: 4.248 eV\n",
      "PM6_1_chlorooctane.aux - HOMO: -10.606 eV, LUMO: 0.949 eV\n",
      "PM6_methyl_acetate.aux - HOMO: -11.003 eV, LUMO: 0.704 eV\n",
      "PM6_o_xylene.aux - HOMO: -9.066 eV, LUMO: 0.534 eV\n",
      "PM6_dichloromethane.aux - HOMO: -10.917 eV, LUMO: 0.116 eV\n",
      "PM6_pentyl_acetate.aux - HOMO: -10.929 eV, LUMO: 0.747 eV\n",
      "PM6_carbon_disulfide.aux - HOMO: -9.653 eV, LUMO: -1.846 eV\n",
      "PM6_diisopropyl_ether.aux - HOMO: -10.111 eV, LUMO: -1.085 eV\n",
      "PM6_3_methoxy_1_butanol.aux - HOMO: -9.725 eV, LUMO: 2.356 eV\n",
      "PM6_cyclopentanol.aux - HOMO: -10.353 eV, LUMO: 3.037 eV\n",
      "PM6_2_2_4_trimethylpentane.aux - HOMO: -10.792 eV, LUMO: 4.159 eV\n",
      "PM6_tert_butylcyclohexane.aux - HOMO: -10.401 eV, LUMO: 3.992 eV\n",
      "PM6_2_pentanol.aux - HOMO: -10.402 eV, LUMO: 2.874 eV\n",
      "PM6_ethylene_glycol.aux - HOMO: -9.832 eV, LUMO: 1.102 eV\n",
      "PM6_undecane.aux - HOMO: -10.729 eV, LUMO: 4.080 eV\n",
      "PM6_1_butanol.aux - HOMO: -10.325 eV, LUMO: 2.877 eV\n",
      "PM6_2_ethyl_1_hexanol.aux - HOMO: -10.276 eV, LUMO: 2.854 eV\n",
      "PM6_2_butoxyethanol.aux - HOMO: -10.062 eV, LUMO: 1.817 eV\n",
      "PM6_dodecane.aux - HOMO: -10.785 eV, LUMO: 4.086 eV\n",
      "PM6_butanone.aux - HOMO: -10.081 eV, LUMO: 0.597 eV\n",
      "PM6_3_7_dimethyl_1_octanol.aux - HOMO: -10.255 eV, LUMO: 2.869 eV\n",
      "PM6_aniline.aux - HOMO: -8.546 eV, LUMO: 0.419 eV\n",
      "PM6_propyl_acetate.aux - HOMO: -10.903 eV, LUMO: 0.775 eV\n",
      "PM6_trans_1_4_dimethylcyclohexane.aux - HOMO: -10.564 eV, LUMO: 3.903 eV\n",
      "PM6_1_4_dioxane.aux - HOMO: -9.682 eV, LUMO: 1.725 eV\n",
      "PM6_carbon_tetrachloride.aux - HOMO: -11.620 eV, LUMO: -1.591 eV\n",
      "PM6_diethyl_ether.aux - HOMO: -9.708 eV, LUMO: 2.389 eV\n",
      "PM6_N_methyl_2_pyrrolidone.aux - HOMO: -9.331 eV, LUMO: 1.173 eV\n",
      "PM6_methyl_tert_butyl_ether.aux - HOMO: -9.728 eV, LUMO: 2.400 eV\n",
      "PM6_1_pentanol.aux - HOMO: -10.339 eV, LUMO: 2.797 eV\n",
      "PM6_methyl_butyrate.aux - HOMO: -10.798 eV, LUMO: 0.807 eV\n",
      "PM6_2_propoxyethanol.aux - HOMO: -9.892 eV, LUMO: 1.792 eV\n",
      "PM6_butyl_acetate.aux - HOMO: -10.906 eV, LUMO: 0.766 eV\n",
      "PM6_decane.aux - HOMO: -10.810 eV, LUMO: 4.141 eV\n",
      "PM6_hexadecane.aux - HOMO: -10.701 eV, LUMO: 3.951 eV\n",
      "PM6_chlorobenzene.aux - HOMO: -9.571 eV, LUMO: -0.084 eV\n",
      "PM6_p_xylene.aux - HOMO: -8.944 eV, LUMO: 0.485 eV\n",
      "PM6_1_2_propanediol.aux - HOMO: -10.400 eV, LUMO: 2.234 eV\n",
      "PM6_dibutyl_ether.aux - HOMO: -10.111 eV, LUMO: -1.086 eV\n",
      "PM6_trifluoroethanol.aux - HOMO: -11.384 eV, LUMO: 1.013 eV\n",
      "PM6_2_methyl_2_propanol.aux - HOMO: -10.449 eV, LUMO: 3.093 eV\n",
      "PM6_DMSO.aux - HOMO: -8.417 eV, LUMO: 0.948 eV\n",
      "PM6_fluorobenzene.aux - HOMO: -9.826 eV, LUMO: -0.040 eV\n",
      "PM6_2_ethoxyethanol.aux - HOMO: -9.706 eV, LUMO: 2.176 eV\n",
      "PM6_octane.aux - HOMO: -10.963 eV, LUMO: 4.072 eV\n",
      "PM6_1_hexanol.aux - HOMO: -10.337 eV, LUMO: 2.873 eV\n",
      "PM6_dimethylacetamide.aux - HOMO: -10.245 eV, LUMO: 1.145 eV\n",
      "PM6_4_methyl_2_pentanol.aux - HOMO: -10.416 eV, LUMO: 2.931 eV\n",
      "PM6_isopropyl_myristate.aux - HOMO: -10.701 eV, LUMO: 0.861 eV\n",
      "PM6_1_2_dibromoethane.aux - HOMO: -10.590 eV, LUMO: -0.439 eV\n",
      "PM6_cyclooctane.aux - HOMO: -10.438 eV, LUMO: 4.399 eV\n",
      "PM6_ethyl_acetate.aux - HOMO: -10.940 eV, LUMO: 0.750 eV\n",
      "PM6_PEG400.aux - HOMO: -9.772 eV, LUMO: 1.118 eV\n",
      "PM6_2_butanol.aux - HOMO: -10.365 eV, LUMO: 2.998 eV\n",
      "PM6_benzyl_alcohol.aux - HOMO: -9.892 eV, LUMO: -0.077 eV\n",
      "PM6_ethanol.aux - HOMO: -10.521 eV, LUMO: 2.878 eV\n",
      "PM6_cis_1_2_dimethylcyclohexane.aux - HOMO: -10.506 eV, LUMO: 4.043 eV\n",
      "PM6_1_propanol.aux - HOMO: -10.348 eV, LUMO: 2.793 eV\n",
      "\n",
      "Success! Processed 102 solvents.\n",
      "Sample results:\n",
      "            Solvent  HOMO (eV)  LUMO (eV)  Band Gap (eV)\n",
      "0         1_octanol    -10.392      2.809         13.201\n",
      "1  propylene_glycol    -10.492      2.203         12.695\n",
      "2       acetic_acid    -11.368      0.429         11.797\n",
      "3           toluene     -9.283      0.447          9.730\n",
      "4            nonane    -10.800      4.006         14.806\n",
      "row count: 102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_mopac_aux(filepath):\n",
    "    \"\"\"Parse MOPAC .aux file to extract HOMO/LUMO energies\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find EIGENVALUES section\n",
    "    eig_match = re.search(r'EIGENVALUES\\[.*?\\]=\\s*((?:-?\\d+\\.\\d+\\s*)+)', content)\n",
    "    if not eig_match:\n",
    "        print(f\"No EIGENVALUES found in {filepath}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Convert scientific notation (1.23D+05 → 1.23e+05) and parse numbers\n",
    "    try:\n",
    "        eig_values = [float(x.replace('D', 'e')) for x in eig_match.group(1).split()]\n",
    "    except:\n",
    "        print(f\"Couldn't parse eigenvalues in {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find OCCUPANCIES section\n",
    "    occ_match = re.search(r'MOLECULAR_ORBITAL_OCCUPANCIES\\[.*?\\]=\\s*((?:\\d+\\.\\d+\\s*)+)', content)\n",
    "    if not occ_match:\n",
    "        print(f\"No OCCUPANCIES found in {filepath}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        occ_values = [float(x) for x in occ_match.group(1).split()]\n",
    "    except:\n",
    "        print(f\"Couldn't parse occupancies in {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    # Verify data\n",
    "    if not eig_values or not occ_values:\n",
    "        print(f\"Empty data in {filepath}\")\n",
    "        return None, None\n",
    "    if len(eig_values) != len(occ_values):\n",
    "        print(f\"Mismatched data lengths in {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    # Find HOMO (last occupied) and LUMO (first unoccupied)\n",
    "    try:\n",
    "        homo_idx = len([occ for occ in occ_values if occ > 0]) - 1\n",
    "        lumo_idx = homo_idx + 1\n",
    "        homo = eig_values[homo_idx]\n",
    "        lumo = eig_values[lumo_idx]\n",
    "        print(f\"{os.path.basename(filepath)} - HOMO: {homo:.3f} eV, LUMO: {lumo:.3f} eV\")\n",
    "        return homo, lumo\n",
    "    except IndexError:\n",
    "        print(f\"Error finding HOMO/LUMO in {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "# Configuration\n",
    "input_dir = \"/Users/stella/Documents/tierney/project/solvent_output_mopac\"\n",
    "output_file = \"/Users/stella/Documents/tierney/project/solvent_homo_lumo.csv\"\n",
    "\n",
    "# Process all PM6_*.aux files\n",
    "results = []\n",
    "for aux_path in glob.glob(os.path.join(input_dir, \"PM6_*.aux\")):\n",
    "    solvent = os.path.basename(aux_path)[4:-4]  # Remove \"PM6_\" and \".aux\"\n",
    "    homo, lumo = parse_mopac_aux(aux_path)\n",
    "    \n",
    "    if homo is not None and lumo is not None:\n",
    "        results.append({\n",
    "            \"Solvent\": solvent,\n",
    "            \"HOMO\": homo,\n",
    "            \"LUMO\": lumo,\n",
    "            \"Band Gap\": lumo - homo\n",
    "        })\n",
    "\n",
    "# Save results\n",
    "if results:\n",
    "    solv_homo_lumo_df = pd.DataFrame(results)\n",
    "    solv_homo_lumo_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSuccess! Processed {len(results)} solvents.\")\n",
    "    print(\"Sample results:\")\n",
    "    print(solv_homo_lumo_df.head())\n",
    "else:\n",
    "    print(\"\\nNo valid data extracted. Check error messages above.\")\n",
    "\n",
    "print(f\"row count: {len(solv_homo_lumo_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Saved 3249 records to:\n",
      "/Users/stella/Documents/tierney/project/solu_homo_lumo.csv\n",
      "\n",
      "Sample data:\n",
      "                      InChIKey             Solvent   HOMO   LUMO\n",
      "0  GVEPBJHOBDJJJI-UHFFFAOYNA-N          chloroform -8.754 -1.359\n",
      "1  GVIJJXMXTUZIOD-UHFFFAOYNA-N         1,4-dioxane -8.529 -0.561\n",
      "2  WBYWAXJHAXSJNI-KZFATGLANA-N             acetone -9.757 -0.747\n",
      "3  RYYVLZVUVIJVGH-UHFFFAOYNA-N             acetone -9.428 -0.709\n",
      "4  GPSDUZXPYCFOSQ-BGGKNDAXNA-N  2-methyl-1-butanol -9.828 -0.881\n",
      "row count: 3249\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_homo_lumo(filepath):\n",
    "    \"\"\"Extract HOMO/LUMO from MOPAC .aux file\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            content = f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Extract EIGENVALUES\n",
    "    eig_match = re.search(r'EIGENVALUES\\[.*?\\]=\\s*((?:-?\\d+\\.\\d+(?:D[+-]\\d+)?\\s*)+)', content)\n",
    "    if not eig_match:\n",
    "        print(f\"No EIGENVALUES in {os.path.basename(filepath)}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Extract OCCUPANCIES\n",
    "    occ_match = re.search(r'MOLECULAR_ORBITAL_OCCUPANCIES\\[.*?\\]=\\s*((?:\\d+\\.\\d+\\s*)+)', content)\n",
    "    if not occ_match:\n",
    "        print(f\"No OCCUPANCIES in {os.path.basename(filepath)}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Convert scientific notation (1.23D+05 → 1.23e+05)\n",
    "        eigenvalues = [float(x.replace('D', 'e')) for x in eig_match.group(1).split()]\n",
    "        occupancies = [float(x) for x in occ_match.group(1).split()]\n",
    "        \n",
    "        # Get HOMO (last occupied) and LUMO (first unoccupied)\n",
    "        homo_idx = len([occ for occ in occupancies if occ > 0]) - 1\n",
    "        return eigenvalues[homo_idx], eigenvalues[homo_idx + 1]\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error in {os.path.basename(filepath)}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Configuration\n",
    "input_dir = \"/Users/stella/Documents/tierney/project/output MOPAC/sol_mopac_files\"\n",
    "output_csv = os.path.join(input_dir, \"/Users/stella/Documents/tierney/project/solu_homo_lumo.csv\")\n",
    "results = []\n",
    "\n",
    "# Process files\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.startswith('PM6_') and filename.endswith('.aux'):\n",
    "        try:\n",
    "            # Extract InChIKey and Solvent from filename (PM6_{inchikey}_{solvent}.aux)\n",
    "            parts = filename[4:-4].split('_')  # Remove 'PM6_' and '.aux'\n",
    "            inchikey = parts[0]\n",
    "            solvent = '_'.join(parts[1:])  # Handle solvents with underscores\n",
    "            \n",
    "            # Parse HOMO/LUMO\n",
    "            full_path = os.path.join(input_dir, filename)\n",
    "            homo, lumo = parse_homo_lumo(full_path)\n",
    "            \n",
    "            if homo is not None and lumo is not None:\n",
    "                results.append({\n",
    "                    'InChIKey': inchikey,\n",
    "                    'Solvent': solvent,\n",
    "                    'HOMO': homo,\n",
    "                    'LUMO': lumo\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "# Create and save DataFrame\n",
    "if results:\n",
    "    solu_homo_lumo_df = pd.DataFrame(results)\n",
    "    solu_homo_lumo_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSuccess! Saved {len(solu_homo_lumo_df)} records to:\\n{output_csv}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(solu_homo_lumo_df.head())\n",
    "else:\n",
    "    print(\"\\nNo valid data found. Check error messages above.\")\n",
    "\n",
    "print(f\"row count: {len(solu_homo_lumo_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before merge: 3249 rows\n",
      "Shape after merge: 3249 rows\n",
      "Missing solvents: ['1,4-dioxane' '2-methyl-1-butanol' '2-butoxyethanol'\n",
      " '4-methyl-2-pentanol' 'peg400' 'dmso' '1-decanol' '2-propanol'\n",
      " '3-methyl-1-butanol' '1-hexanol' '2-methyl-1-propanol' '1-heptanol'\n",
      " '1-propanol' '1-butanol' 'n-methylformamide' '1-pentanol' 'o-xylene'\n",
      " 'thf' '1-octanol' '3-methoxy-1-butanol' '2-ethoxyethanol' '2-pentanol'\n",
      " '2-methyl-2-propanol' '2-ethyl-1-hexanol' '1,2-dichloroethane'\n",
      " '2-methyl-1-pentanol' '2-butanol' 'p-xylene'\n",
      " 'cis-1,2-dimethylcyclohexane' '2-propoxyethanol' 'm-xylene'\n",
      " 'tert-butylcyclohexane' '2-isopropoxyethanol' 'n-methyl-2-pyrrolidone'\n",
      " '1-tert-butoxy-2-propanol' '3,7-dimethyl-1-octanol' '1-chlorobutane'\n",
      " 'cis-1,4-dimethylcyclohexane' '2,2,4-trimethylpentane' 'dmf'\n",
      " 'cis-1,3-dimethylcyclohexane' '2-methyl-2-butanol' '1,2-propanediol'\n",
      " 'trans-1,2-dimethylcyclohexane' 'trans-1,4-dimethylcyclohexane'\n",
      " '1-chlorooctane' '1,2-dibromoethane']\n",
      "Final columns: ['InChIKey', 'Solvent', 'HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv', 'Lsolu_Hsolv', 'Lsolv_Hsolu']\n",
      "row count: 3249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_solv_homo_lumo = pd.read_csv(\"/Users/stella/Documents/tierney/project/solvent_homo_lumo.csv\")\n",
    "df_solu_homo_lumo = pd.read_csv(\"/Users/stella/Documents/tierney/project/solu_homo_lumo.csv\")\n",
    "\n",
    "# Convert to float\n",
    "df_solv_homo_lumo['HOMO'] = df_solv_homo_lumo['HOMO'].astype(float)\n",
    "df_solv_homo_lumo['LUMO'] = df_solv_homo_lumo['LUMO'].astype(float)\n",
    "df_solu_homo_lumo['HOMO'] = df_solu_homo_lumo['HOMO'].astype(float)\n",
    "df_solu_homo_lumo['LUMO'] = df_solu_homo_lumo['LUMO'].astype(float)\n",
    "\n",
    "# Merge DataFrames (keep all solute rows)\n",
    "merged_df = pd.merge(\n",
    "    df_solu_homo_lumo,\n",
    "    df_solv_homo_lumo[['Solvent', 'HOMO', 'LUMO']],\n",
    "    on='Solvent',\n",
    "    how='left',\n",
    "    suffixes=('_solu', '_solv')\n",
    ")\n",
    "\n",
    "# Calculate descriptors\n",
    "merged_df['Lsolu_Hsolv'] = merged_df['LUMO_solu'] - merged_df['HOMO_solv']\n",
    "merged_df['Lsolv_Hsolu'] = merged_df['LUMO_solv'] - merged_df['HOMO_solu']\n",
    "\n",
    "# Save to CSV\n",
    "merged_df.to_csv(\"/Users/stella/Documents/tierney/project/merged_results.csv\", index=False)\n",
    "\n",
    "# Verify\n",
    "print(\"Shape before merge:\", df_solu_homo_lumo.shape[0], \"rows\")\n",
    "print(\"Shape after merge:\", merged_df.shape[0], \"rows\")\n",
    "print(\"Missing solvents:\", merged_df[merged_df['HOMO_solv'].isna()]['Solvent'].unique())\n",
    "\n",
    "# Drop the original HOMO/LUMO columns if needed\n",
    "homo_lumo_df = merged_df.drop(['HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv'], axis=1)\n",
    "\n",
    "# keep the original df_solu_homo_lumo structure:\n",
    "df_solu_homo_lumo = merged_df\n",
    "\n",
    "\n",
    "print(f\"Final columns: {merged_df.columns.tolist()}\")\n",
    "print(f\"row count: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before merge: 3249 rows\n",
      "Shape after merge: 3249 rows\n",
      "Missing solvents: []\n",
      "Final columns: ['InChIKey', 'Solvent', 'Lsolu_Hsolv', 'Lsolv_Hsolu']\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files (assuming you haven't done this yet)\n",
    "import pandas as pd\n",
    "\n",
    "df_solv_homo_lumo = pd.read_csv(\"/Users/stella/Documents/tierney/project/solvent_homo_lumo.csv\")\n",
    "df_solu_homo_lumo = pd.read_csv(\"/Users/stella/Documents/tierney/project/solu_homo_lumo.csv\")\n",
    "\n",
    "# Convert to float\n",
    "df_solv_homo_lumo['HOMO'] = df_solv_homo_lumo['HOMO'].astype(float)\n",
    "df_solv_homo_lumo['LUMO'] = df_solv_homo_lumo['LUMO'].astype(float)\n",
    "df_solu_homo_lumo['HOMO'] = df_solu_homo_lumo['HOMO'].astype(float)\n",
    "df_solu_homo_lumo['LUMO'] = df_solu_homo_lumo['LUMO'].astype(float)\n",
    "\n",
    "# Replace underscores with hyphens/commas in df_solv_homo_lumo\n",
    "df_solv_homo_lumo['Solvent'] = df_solv_homo_lumo['Solvent'].str.replace('_', '-')\n",
    "# Special case for \"1,4-dioxane\" (replace \"1-4\" with \"1,4\")\n",
    "df_solv_homo_lumo['Solvent'] = df_solv_homo_lumo['Solvent'].str.replace('1-4', '1,4')\n",
    "\n",
    "missing_data = {\n",
    "    'Solvent': ['peg400', 'dmso', 'n-methylformamide', 'thf', '1,2-dichloroethane',\n",
    "               'cis-1,2-dimethylcyclohexane', 'n-methyl-2-pyrrolidone',\n",
    "               '3,7-dimethyl-1-octanol', '2,2,4-trimethylpentane', 'dmf',\n",
    "               'cis-1,3-dimethylcyclohexane', '1,2-propanediol',\n",
    "               'trans-1,2-dimethylcyclohexane', '1,2-dibromoethane'],\n",
    "    'HOMO': [-9.772, -8.417, -9.962, -9.54, -10.79,\n",
    "            -10.506, -9.331, -10.255, -10.792, -9.435,\n",
    "            -10.533, -10.4, -10.559, -10.59],\n",
    "    'LUMO': [1.118, 0.948, 1.024, 2.345, 0.425,\n",
    "            4.043, 1.173, 2.869, 4.159, 1.134,\n",
    "            4.012, 2.234, 3.96, -0.439],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and add to existing solvent data\n",
    "df_solv_homo_lumo = pd.concat([\n",
    "    df_solv_homo_lumo, \n",
    "    pd.DataFrame(missing_data)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Merge DataFrames (keep all solute rows)\n",
    "merged_df = pd.merge(\n",
    "    df_solu_homo_lumo,\n",
    "    df_solv_homo_lumo[['Solvent', 'HOMO', 'LUMO']],\n",
    "    on='Solvent',\n",
    "    how='left',\n",
    "    suffixes=('_solu', '_solv')\n",
    ")\n",
    "\n",
    "# Calculate descriptors\n",
    "merged_df['Lsolu_Hsolv'] = merged_df['LUMO_solu'] - merged_df['HOMO_solv']\n",
    "merged_df['Lsolv_Hsolu'] = merged_df['LUMO_solv'] - merged_df['HOMO_solu']\n",
    "\n",
    "# Save to CSV\n",
    "merged_df.to_csv(\"/Users/stella/Documents/tierney/project/homo_lumo.csv\", index=False)\n",
    "\n",
    "# Verify\n",
    "print(\"Shape before merge:\", df_solu_homo_lumo.shape[0], \"rows\")\n",
    "print(\"Shape after merge:\", merged_df.shape[0], \"rows\")\n",
    "print(\"Missing solvents:\", merged_df[merged_df['HOMO_solv'].isna()]['Solvent'].unique())\n",
    "\n",
    "# Drop the original HOMO/LUMO columns\n",
    "homo_lumo_df = merged_df.drop(['HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv'], axis=1)\n",
    "homo_lumo_df.to_csv(\"/Users/stella/Documents/tierney/project/homo_lumo.csv\", index=False)\n",
    "print(f\"Final columns: {homo_lumo_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns: ['InChIkey', 'Solvent', 'HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv', 'Lsolu_Hsolv', 'Lsolv_Hsolu']\n"
     ]
    }
   ],
   "source": [
    "homo_lumo_df = merged_df.drop(['HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv'], axis=1)\n",
    "merged_df.to_csv(\"/Users/stella/Documents/tierney/project/merged_results.csv\", index=False)\n",
    "print(f\"Final columns: {merged_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'LUMO_solu', 'HOMO_solv', 'LUMO_solv'], axis=1)\n",
    "merged_df.to_csv(\"/Users/stella/Documents/tierney/project/merged_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m2/ptj22ckn1lq9dwc6k6bwvz580000gn/T/ipykernel_17703/4216203270.py:73: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_charges = pd.concat([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for 3249 compounds to /Users/stella/Documents/tierney/project/charge_descriptors.csv\n",
      "                      InChIkey             Solvent O_charges  C_charges  \\\n",
      "0  GVEPBJHOBDJJJI-UHFFFAOYNA-N          chloroform         0   -1.61070   \n",
      "1  GVIJJXMXTUZIOD-UHFFFAOYNA-N         1,4-dioxane         0   -1.27891   \n",
      "2  WBYWAXJHAXSJNI-KZFATGLANA-N             acetone  -1.10051   -0.44112   \n",
      "3  RYYVLZVUVIJVGH-UHFFFAOYNA-N             acetone   -1.2109    0.32621   \n",
      "4  GPSDUZXPYCFOSQ-BGGKNDAXNA-N  2-methyl-1-butanol   -1.0889   -0.48849   \n",
      "\n",
      "   Most_neg  Most_pos Het_charges  \n",
      "0  -0.15618   0.16410           0  \n",
      "1  -0.13958   0.16914    -0.03833  \n",
      "2  -0.60299   0.68712    -1.10051  \n",
      "3  -0.60868   0.69004    -2.22267  \n",
      "4  -0.60654   0.65746     -1.0889  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_index_positions(list_of_elems, element):\n",
    "    return [i for i, x in enumerate(list_of_elems) if x == element]\n",
    "\n",
    "def parse_section(lines, start_marker):\n",
    "    \"\"\"Helper function to parse multi-line sections\"\"\"\n",
    "    section_data = []\n",
    "    capturing = False\n",
    "    for line in lines:\n",
    "        if start_marker in line:\n",
    "            capturing = True\n",
    "            continue\n",
    "        if capturing:\n",
    "            if ']=' in line:  # End of section\n",
    "                break\n",
    "            section_data.extend(line.strip().split())\n",
    "    return section_data\n",
    "\n",
    "def get_charge_descriptors(sol_path):\n",
    "    df_charges = pd.DataFrame(columns=['InChIkey', 'Solvent', 'O_charges', 'C_charges',\n",
    "                                     'Most_neg', 'Most_pos', 'Het_charges'])\n",
    "\n",
    "    for filename in os.listdir(sol_path):\n",
    "        if not filename.endswith('.aux'):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Extract InChIkey and solvent\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 3:\n",
    "                print(f\"Skipping bad filename: {filename}\")\n",
    "                continue\n",
    "                \n",
    "            inchikey = parts[1]\n",
    "            solvent = parts[2].replace('.aux', '')\n",
    "\n",
    "            # Read file\n",
    "            with open(os.path.join(sol_path, filename), 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Parse atoms (handles multi-line ATOM_EL)\n",
    "            atoms = parse_section(lines, 'ATOM_EL[')\n",
    "            \n",
    "            # Parse charges (handles multi-line ATOM_CHARGES)\n",
    "            charges = parse_section(lines, 'ATOM_CHARGES[')\n",
    "\n",
    "            # Validate\n",
    "            if not atoms or not charges:\n",
    "                print(f\"Skipping {filename}: missing atom or charge data\")\n",
    "                continue\n",
    "                \n",
    "            if len(charges) != len(atoms):\n",
    "                print(f\"Debug {filename}: {len(atoms)} atoms, charges: {charges[:10]}...\")\n",
    "                continue\n",
    "\n",
    "            # Convert charges\n",
    "            try:\n",
    "                charges_number = [float(x) for x in charges]\n",
    "            except ValueError:\n",
    "                print(f\"Charge conversion failed in {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate descriptors\n",
    "            O_charges = sum(charges_number[i] for i in get_index_positions(atoms, 'O'))\n",
    "            C_charges = sum(charges_number[i] for i in get_index_positions(atoms, 'C'))\n",
    "            Most_pos = max(charges_number)\n",
    "            Most_neg = min(charges_number)\n",
    "            Het_charges = sum(c for a, c in zip(atoms, charges_number) if a not in {'C', 'H'})\n",
    "\n",
    "            # Store results\n",
    "            df_charges = pd.concat([\n",
    "                df_charges,\n",
    "                pd.DataFrame([{\n",
    "                    'InChIkey': inchikey,\n",
    "                    'Solvent': solvent,\n",
    "                    'O_charges': O_charges,\n",
    "                    'C_charges': C_charges,\n",
    "                    'Most_neg': Most_neg,\n",
    "                    'Most_pos': Most_pos,\n",
    "                    'Het_charges': Het_charges\n",
    "                }])\n",
    "            ], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    return df_charges\n",
    "\n",
    "# Usage\n",
    "sol_path = '/Users/stella/Documents/tierney/project/output MOPAC/sol_mopac_files'\n",
    "df_charges = get_charge_descriptors(sol_path)\n",
    "\n",
    "# Save and show results\n",
    "output_path = '/Users/stella/Documents/tierney/project/charge_descriptors.csv'\n",
    "df_charges.to_csv(output_path, index=False)\n",
    "print(f\"Saved results for {len(df_charges)} compounds to {output_path}\")\n",
    "print(df_charges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names check:\n",
      "df_thermo: ['InChIkey', 'Solvent', 'G_sol', 'DeltaG_sol']\n",
      "df_dip_vol: ['volume', 'sol_dip', 'InChIkey', 'Solvent']\n",
      "merged_df: ['InChIkey', 'Solvent', 'HOMO_solu', 'LUMO_solu', 'HOMO_solv', 'LUMO_solv', 'Lsolu_Hsolv', 'Lsolv_Hsolu']\n",
      "df_charges: ['InChIkey', 'Solvent', 'O_charges', 'C_charges', 'Most_neg', 'Most_pos', 'Het_charges']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_thermo = pd.read_csv('/Users/stella/Documents/tierney/project/G_thermo_data.csv')\n",
    "df_dip_vol = pd.read_csv('/Users/stella/Documents/tierney/project/dip_data.csv')\n",
    "merged_df = pd.read_csv('/Users/stella/Documents/tierney/project/merged_results.csv')\n",
    "df_charges = pd.read_csv('/Users/stella/Documents/tierney/project/charge_descriptors.csv')\n",
    "\n",
    "# 1. First check column names in each DataFrame\n",
    "print(\"Column names check:\")\n",
    "print(\"df_thermo:\", df_thermo.columns.tolist())\n",
    "print(\"df_dip_vol:\", df_dip_vol.columns.tolist())\n",
    "print(\"merged_df:\", merged_df.columns.tolist())\n",
    "print(\"df_charges:\", df_charges.columns.tolist())\n",
    "\n",
    "df_thermo_dip_vol = pd.merge(df_thermo, df_dip_vol, on='InChIkey')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thermo_dip_vol_homo_lumo = pd.merge(df_thermo_dip_vol, merged_df, on='InChIkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_thermo_dip_vol_homo_lumo, df_charges, on='InChIkey')\n",
    "\n",
    "print(f\"Merged DataFrame shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame shape: (89323553, 19)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Merged DataFrame shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row counts:\n",
      "df_thermo: 3249 rows\n",
      "df_dip_vol: 3249 rows\n",
      "merged_df: 3249 rows\n",
      "df_charges: 3249 rows\n",
      "thermo duplicates: 0\n",
      "dip_vol duplicates: 0\n",
      "homo_lumo duplicates: 0\n",
      "charges duplicates: 0\n",
      "\n",
      "Final merged shape: (3249, 13)\n",
      "Expected columns: ['InChIkey', 'Solvent', 'G_sol', 'DeltaG_sol', 'volume', 'sol_dip', 'Lsolu_Hsolv', 'Lsolv_Hsolu', 'O_charges', 'C_charges', 'Most_neg', 'Most_pos', 'Het_charges']\n",
      "Sample data:\n",
      "                      InChIkey                 Solvent      G_sol  DeltaG_sol  \\\n",
      "0  AAOVKJBEBIDNHE-UHFFFAOYNA-N  n-methyl-2-pyrrolidone -29429.188   -877.9704   \n",
      "1  AAOVKJBEBIDNHE-UHFFFAOYNA-N               1-octanol -29190.814   -639.5964   \n",
      "2  AAOVKJBEBIDNHE-UHFFFAOYNA-N                   water -29262.224   -711.0064   \n",
      "3  AAOVKJBEBIDNHE-UHFFFAOYNA-N                 ethanol -29257.446   -706.2284   \n",
      "4  ACWBQPMHZXGDFX-XGLYSIDGNA-N              chloroform -41792.200  -1033.5428   \n",
      "\n",
      "    volume  sol_dip  Lsolu_Hsolv  Lsolv_Hsolu  O_charges  C_charges  Most_neg  \\\n",
      "0  324.523  5.79992        8.360       10.526   -0.61255   -0.92733  -0.61255   \n",
      "1  323.693  5.70941        9.426       12.158   -0.60938   -0.93230  -0.60938   \n",
      "2  144.069  3.44129       10.795       13.316   -0.62825   -0.92974  -0.62825   \n",
      "3  324.605  5.95922        9.551       12.233   -0.62160   -0.93091  -0.62160   \n",
      "4  202.999  3.79675       10.551        8.860   -1.68816   -2.32011  -0.62564   \n",
      "\n",
      "   Most_pos  Het_charges  \n",
      "0   0.59939     -1.39092  \n",
      "1   0.59912     -1.38218  \n",
      "2   0.60141     -1.41014  \n",
      "3   0.60065     -1.40012  \n",
      "4   0.63507     -2.63228  \n",
      "\n",
      "Saved 3249 rows to /Users/stella/Documents/tierney/project/total_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_thermo = pd.read_csv('/Users/stella/Documents/tierney/project/G_thermo_data.csv')\n",
    "df_dip_vol = pd.read_csv('/Users/stella/Documents/tierney/project/dip_data.csv')\n",
    "merged_df = pd.read_csv('/Users/stella/Documents/tierney/project/homo_lumo.csv')\n",
    "df_charges = pd.read_csv('/Users/stella/Documents/tierney/project/charge_descriptors.csv')\n",
    "# 1. Verify expected row counts\n",
    "print(\"Original row counts:\")\n",
    "print(f\"df_thermo: {len(df_thermo)} rows\")\n",
    "print(f\"df_dip_vol: {len(df_dip_vol)} rows\") \n",
    "print(f\"merged_df: {len(merged_df)} rows\")\n",
    "print(f\"df_charges: {len(df_charges)} rows\")\n",
    "\n",
    "# 2. Check for duplicate InChIkey+Solvent combinations\n",
    "for name, df in [('thermo', df_thermo), ('dip_vol', df_dip_vol),\n",
    "                 ('homo_lumo', merged_df), ('charges', df_charges)]:\n",
    "    dupes = df.duplicated(subset=['InChIkey', 'Solvent']).sum()\n",
    "    print(f\"{name} duplicates: {dupes}\")\n",
    "    if dupes > 0:\n",
    "        df = df.drop_duplicates(subset=['InChIkey', 'Solvent'], keep='first')\n",
    "\n",
    "# 3. Perform the corrected merge - CRITICAL STEP\n",
    "# Merge on BOTH InChIkey AND Solvent\n",
    "df_all = (df_thermo\n",
    "          .merge(df_dip_vol, on=['InChIkey', 'Solvent'], how='inner')\n",
    "          .merge(merged_df, on=['InChIkey', 'Solvent'], how='inner')\n",
    "          .merge(df_charges, on=['InChIkey', 'Solvent'], how='inner'))\n",
    "\n",
    "# 4. Verify final output\n",
    "print(f\"\\nFinal merged shape: {df_all.shape}\")\n",
    "print(\"Expected columns:\", df_all.columns.tolist())\n",
    "print(\"Sample data:\")\n",
    "print(df_all.head())\n",
    "\n",
    "# 5. Save results\n",
    "output_path = '/Users/stella/Documents/tierney/project/total_data.csv'\n",
    "df_all.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved {len(df_all)} rows to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row counts and columns:\n",
      "\n",
      "thermo:\n",
      "Rows: 3249\n",
      "Columns: ['InChIkey', 'Solvent', 'G_sol', 'DeltaG_sol']\n",
      "\n",
      "dip_vol:\n",
      "Rows: 3249\n",
      "Columns: ['volume', 'sol_dip', 'InChIkey', 'Solvent']\n",
      "\n",
      "homo_lumo:\n",
      "Rows: 3249\n",
      "Columns: ['InChIKey', 'Solvent', 'Lsolu_Hsolv', 'Lsolv_Hsolu']\n",
      "\n",
      "charges:\n",
      "Rows: 3249\n",
      "Columns: ['InChIkey', 'Solvent', 'O_charges', 'C_charges', 'Most_neg', 'Most_pos', 'Het_charges']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 1. Verify expected row counts and columns\n",
    "print(\"Original row counts and columns:\")\n",
    "for name, df in [('thermo', df_thermo), ('dip_vol', df_dip_vol),\n",
    "                 ('homo_lumo', merged_df), ('charges', df_charges)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Rows: {len(df)}\")\n",
    "    print(\"Columns:\", df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
