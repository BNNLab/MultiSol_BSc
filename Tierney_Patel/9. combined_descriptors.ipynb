{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns:\n",
      "final_reduced: solute_inchikey (solute), Solvent (solvent)\n",
      "all_data: InChIkey (solute), Solvent (solvent)\n",
      "\n",
      "Successfully matched 3249/3249 rows (100.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "final_reduced = pd.read_csv('final_reduced_dataset.csv')\n",
    "all_data = pd.read_csv('all_data.csv')\n",
    "\n",
    "# Function to find matching column\n",
    "def find_column(df, possible_names):\n",
    "    for name in possible_names:\n",
    "        if name in df.columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# Possible column name variations (add more if needed)\n",
    "solute_possibilities = [\n",
    "    'solute_inchikey', 'inchikey', 'InChIkey', 'solute_InChIKey', \n",
    "    'Solute_InChIKey', 'inchi_key', 'InChI_Key', 'mol_id'\n",
    "]\n",
    "solvent_possibilities = [\n",
    "    'Solvent', 'solvent', 'Solvent_Name', 'solvent_name', \n",
    "    'solvent_id', 'solvent_name'\n",
    "]\n",
    "\n",
    "# Find actual column names\n",
    "solute_final = find_column(final_reduced, solute_possibilities)\n",
    "solvent_final = find_column(final_reduced, solvent_possibilities)\n",
    "solute_all = find_column(all_data, solute_possibilities)\n",
    "solvent_all = find_column(all_data, solvent_possibilities)\n",
    "\n",
    "# Verify we found all necessary columns\n",
    "if not all([solute_final, solvent_final, solute_all, solvent_all]):\n",
    "    print(\"ERROR: Could not find all required columns.\")\n",
    "    print(f\"final_reduced columns: Solute - {solute_final}, Solvent - {solvent_final}\")\n",
    "    print(f\"all_data columns: Solute - {solute_all}, Solvent - {solvent_all}\")\n",
    "    print(\"\\nActual columns in final_reduced:\", final_reduced.columns.tolist())\n",
    "    print(\"Actual columns in all_data:\", all_data.columns.tolist())\n",
    "else:\n",
    "    print(f\"Using columns:\\n\"\n",
    "          f\"final_reduced: {solute_final} (solute), {solvent_final} (solvent)\\n\"\n",
    "          f\"all_data: {solute_all} (solute), {solvent_all} (solvent)\")\n",
    "\n",
    "    # Create mapping dictionary (case insensitive)\n",
    "    final_reduced['key1'] = final_reduced[solute_final].astype(str).str.lower().str.strip()\n",
    "    final_reduced['key2'] = final_reduced[solvent_final].astype(str).str.lower().str.strip()\n",
    "    logS_map = final_reduced.set_index(['key1', 'key2'])['LogS'].to_dict()\n",
    "\n",
    "    # Add LogS column with case insensitive matching\n",
    "    all_data['temp_key1'] = all_data[solute_all].astype(str).str.lower().str.strip()\n",
    "    all_data['temp_key2'] = all_data[solvent_all].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # Track missing matches\n",
    "    missing = []\n",
    "    \n",
    "    def get_logs(row):\n",
    "        key = (row['temp_key1'], row['temp_key2'])\n",
    "        if key not in logS_map:\n",
    "            missing.append(key)\n",
    "            return None\n",
    "        return logS_map[key]\n",
    "    \n",
    "    all_data['LogS'] = all_data.apply(get_logs, axis=1)\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    all_data.drop(['temp_key1', 'temp_key2'], axis=1, inplace=True)\n",
    "    \n",
    "    # Save results\n",
    "    all_data.to_csv('all_data_with_LogS.csv', index=False)\n",
    "    \n",
    "    # Report statistics\n",
    "    total = len(all_data)\n",
    "    matched = total - len(missing)\n",
    "    print(f\"\\nSuccessfully matched {matched}/{total} rows ({matched/total:.1%})\")\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"{len(missing)} rows had no matching LogS value\")\n",
    "        # Save missing keys for investigation\n",
    "        pd.DataFrame(missing, columns=['solute_key', 'solvent_key'])\\\n",
    "          .to_csv('missing_logs_matches.csv', index=False)\n",
    "        print(\"Missing matches saved to missing_logs_matches.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing LogS values: 43\n",
      "\n",
      "Sample rows with missing LogS:\n",
      "                        InChIkey       Solvent       MW     SASA      G_sol  \\\n",
      "50   CIWBSHSKHKDKBQ-JLAZNSOCNA-N       toluene  176.126  180.498 -24465.056   \n",
      "93   ZYVHVGJGLOEEKD-FQFUPTBWNA-N       toluene  286.243  296.542 -30777.268   \n",
      "224  BXAOUWIVXLQYOZ-SPEPDGBUNA-N   cyclohexane  443.542  446.815 -44890.280   \n",
      "233  GSBSDUZVSCTUKA-PKSOQXRJNA-N        hexane  288.345  298.929 -28673.942   \n",
      "287  GSBSDUZVSCTUKA-PKSOQXRJNA-N  acetonitrile  288.345  305.724 -29034.254   \n",
      "\n",
      "      DeltaG_sol   Volume  sol_dip  LsoluHsolv  LsolvHsolu  O_charges  \\\n",
      "50   -534.012500  236.332  2.65075       8.161      10.370   -2.78640   \n",
      "93  -1081.589000  311.673  4.43134       7.288      10.665   -2.63331   \n",
      "224  -304.913867  239.587  1.67927      10.171      13.314   -2.45614   \n",
      "233     2.388933  182.922  4.16798       9.706      12.450   -1.05470   \n",
      "287  -357.923067  346.342  3.45279      11.302       9.546   -1.11621   \n",
      "\n",
      "     C_charges  Most_neg  Most_pos  Het_charges  LogS  \n",
      "50     0.72858  -0.55243   0.62052     -2.78640   NaN  \n",
      "93     0.22270  -0.57377   0.64576     -2.39529   NaN  \n",
      "224   -2.19151  -0.61682   0.72406     -3.77938   NaN  \n",
      "233   -1.69774  -0.56459   0.64364     -1.05470   NaN  \n",
      "287   -1.78915  -0.61393   0.67192     -1.11621   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged data\n",
    "merged_data = pd.read_csv('all_data_with_LogS.csv')\n",
    "\n",
    "# Check for null values in LogS column\n",
    "null_logs = merged_data['LogS'].isnull().sum()\n",
    "print(f\"Number of rows with missing LogS values: {null_logs}\")\n",
    "\n",
    "# Show sample rows with missing LogS\n",
    "if null_logs > 0:\n",
    "    print(\"\\nSample rows with missing LogS:\")\n",
    "    print(merged_data[merged_data['LogS'].isnull()].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average LogS by solvent\n",
    "solvent_avg = merged_data.groupby('Solvent')['LogS'].mean()\n",
    "\n",
    "# Fill missing LogS values with solvent averages\n",
    "merged_data['LogS'] = merged_data.apply(\n",
    "    lambda row: solvent_avg[row['Solvent']] if pd.isnull(row['LogS']) else row['LogS'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save the final data\n",
    "merged_data.to_csv('all_data_with_LogS_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing LogS values: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged data\n",
    "merged_data = pd.read_csv('all_data_with_LogS_final.csv')\n",
    "\n",
    "# Check for null values in LogS column\n",
    "null_logs = merged_data['LogS'].isnull().sum()\n",
    "print(f\"Number of rows with missing LogS values: {null_logs}\")\n",
    "\n",
    "# Show sample rows with missing LogS\n",
    "if null_logs > 0:\n",
    "    print(\"\\nSample rows with missing LogS:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
